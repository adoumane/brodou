

\section{Linear time \mucalculus and its proof systems}
In this section we introduce the linear time \mucalculus and its semantics,
together with two proof systems. The first one, \muLK, is the proof system introduced by Kaivola in \cite{kaivola95concur}, but written in a sequent calculus fashion. This system is the target of our completeness result.  The second one is  the circular proof system \muLKo, which will serve as an intermediary proof system for the proof of completeness. At the end of this section, we show a link 
between this two proof systems. 

\subsection{Syntax and semantics}

\begin{definition}
Let $\C{V}=\{X,Y,\dots \}$ be a set of variables and
$\At =\{\mathfrak{p},\mathfrak{q},\dots\}$ a set of atoms.
Linear time \mucalculus \defname{formulas} $\phi, \psi, \ldots$
are given by:
\renewcommand{\|}{\mathrel{|}}
$$ \null\hfill
   \phi ::=  \mathfrak{p} \|\neg\mathfrak{p}  \| X \| \phi \vee \phi \|
   \phi \wedge \phi \| \odot \phi \|
   \mu X. \phi \| \nu X. \phi
   \hfill\null
$$ 
The connectives $\mu$ and $\nu$ bind the variable $X$ in $\phi$.
From there, bound variables, free variables and capture-avoiding
substitution are defined in a standard way. The subformula ordering is denoted 
$\leq$ and $\fv(\bullet)$ denotes free variables. Atoms and their negations are called \textbf{litterals}.
We shall use $\sigma$ to denote either $\mu$ or $\nu$.
\end{definition}
Note that we do not allow negations on variables. This is not a restriction
since we are mostly interested in closed formulas. All the results presented
here extend to the general case, where negations are allowed under a
positivity condition on bound variables. We do not consider the boolean constants $\top, \bot$ as they can be encoded
by $\top:= \nu X. \odot X$ and $\bot:=\mu X. \odot X$.

The models of our formulas are the $\omega$-words over the alphabet $\Sigma:=2^{\At}$. Intuitively, every position of such a word correponds to an instant of time, and a letter at some position represents the set of atoms true at 
the  corresponding instant of time. In the example below, 
atoms $\mathfrak{p}, \mathfrak{q}$ are true at instant $0$, atoms  $\mathfrak{q}, \mathfrak{r}$ are true at instant $1$, etc. We define the semantics of a formula wrt. a model to be the set of instants of time where the formula holds in this model.  
\begin{center}
\scalebox{.99}{
\begin{tikzpicture}[shorten >=1pt, node distance=2cm, auto]
   \node[state , fill=black!25]         (0)                          {$\mathfrak{p}, \mathfrak{q}$};
   \node[state,  fill=black!25]         (1)   [right of= 0]           {$\mathfrak{q}, \mathfrak{r}$};
   \node[state,  fill=black!25]         (2)   [right of = 1]           {$\mathfrak{p}$};
   \node                            (3)   [right of = 2]           {$\dots$};
 
  \path[->]
             (0)  edge                node           {}   (1)
             (1)  edge                node           {}   (2)
             (2)  edge                node           {}   (3);
\end{tikzpicture}} 
\end{center}
\begin{definition}\label{def:semantics}
The \defname{semantics} $\semantics{\phi}^u_\rho$ of a formula $F$ wrt. $u \in\Sigma^\omega$
and a valuation $\rho: \C V \mapsto 2^\omega$ 
is a subset of natural numbers
inductively defined as follows:\\
$\begin{array}{l}
{\semantics{\mathfrak{p}}}^u_\rho = \{ i\in\omega \mid \mathfrak{p}\in u_i\}
 \quad\ 
{\semantics {\mathfrak{p}^\bot}}^u_\rho = \{ i\in\omega \mid \mathfrak{p}\notin u_i\}
\\
{\semantics X}^u_\rho = \rho(X)
\qquad\qquad\quad\ \ {\semantics {\Next \phi}}^u_\rho = \{ i\in\omega\mid i+1\in {\semantics {\phi}}^u_\rho\}
\\
  {\semantics {\phi\vee \psi}}^u_\rho = {\semantics \phi}^u_\rho \cup {\semantics \psi}^u_\rho
\ \ {\semantics {\phi\wedge \psi}}^u_\rho = {\semantics \phi}^u_\rho \cap {\semantics \psi}^u_\rho\\
\end{array}$\\
$\begin{array}{l}
 {\semantics {\nu X. \phi}}^u_\rho = \bigcup \{\;W\subseteq\omega \mid W \subseteq {\semantics{\phi}}^u_{\rho[X \leftarrow W]}\;\}
\\
{\semantics {\mu X. \phi}}^u_\rho = \bigcap \{\;W\subseteq \omega \mid \semantics{\phi}^u_{\rho[X \leftarrow W]} \subseteq W\;\}
\\
\end{array}$\\
Suppose that $\phi$ is a closed formula.
 We write $\semantics{\phi}^u$ instead of $ \semantics{\phi}^u_\rho$, since the semantics of $\phi$ do not depend on $\rho$. We say that $\phi$ is \defname{true}
in  $u$, and we write $u\models \phi$, if $0\in \semantics{\phi}^u$. 
The set of \defname{models of $\phi$} is defined by 
$\C{M}(\phi)= \{u\in\Sigma^\omega \mid u\models \phi\}$.
A formula is \defname{valid} if it is true in every model, ie. $\C{M}(\phi)=\Sigma^\omega$. 
\end{definition}

\subsection{Proof systems for linear time \mucalculus}

There are many possible presentations of sequent calculus, which differ 
mainly by the way sequents are defined. Sometimes sequents are presented as
 sets or multisets of formulas, but most proof theoretical observations, namely
the proofs-as-programms correspondance,  actually hold in a 
stronger setting where sequents  are sets of \emph{occurrences} of formula.
We chose to work with this later presentation  for two reasons: first, in the 
 perspective of considering proofs as certificates, one may want to run these certificates (eg., extract examples or algorithms
from them), thus the need for a frawework where proofs can be  seen as programs; the second reason is technical, since some 
transformations we perform  on proofs (\ref{}) require precisely this viewpoint.
We present below the notion of occurrence and use it to build our two proof systems \muLK and \muLKo.

\subsubsection{Occurrences}\label{sec:formulaOcc}


\begin{definition}
  An \defname{address} is a word over $\{\Al,\Ar,\Ai\}$,
  which stands for left, right and inside.
  We say that $\alpha'$ is a \defname{sub-address} of $\alpha$
  when $\alpha$ is a prefix of $\alpha'$,
  written $\alpha \sqsubseteq \alpha'$.
  We say that $\alpha$ and $\beta$ are \defname{disjoint} when
  $\alpha$ and $\beta$ have no upper bound wrt.\ ${\sqsubseteq}$.
\end{definition}

\begin{definition}\label{def:OperationsOccurrences}
  An \defname{occurrence} (denoted by $F$, $G$, $H$)
  is given by a formula $\phi$ and an address $\alpha$, and written 
  $\phi_\alpha$.  We say that rwo occurrences are \defname{disjoint} when their
 addresses  are.
Let $F=\phi_\alpha$ be an
occurrence and $\beta$ an adress. We define $F_\beta$ to be $F_\beta=\phi_\beta$ . We say that we
\defname{relocated F in $\beta$}. We define $\overline{F}$ to be $\overline{F}=\phi$. The function $\overline{.}$ is called the
forgetfull function. We write $F\equiv G$ if $\overline{F}=\overline{G}$.
  %
  Operations on formulas are extended to occurrences as follows:
  for any $\star\in\{\vee, \wedge\}$,
  $F\star G = (\phi\star\psi)_\alpha$ if
  $F = \phi_{\alpha \Al}$ and
  $G = \psi_{\alpha \Ar}$;
  $\sigma X. F = (\sigma X. \phi)_\alpha$ and $\odot F=(\odot\phi)_\alpha$ if $F = \phi_{\alpha\Ai}$;
  we also allow ourselves to write litterals  as occurrences without
  specifying their address, which can be chosen arbitrarily.
  \defname{Substitution of occurrences} is defined by
  $(\phi_\alpha)[\psi_\beta/X] = (\phi[\psi/X])_\alpha$.
\end{definition}


\comad{Proviso sur l'utilsation de formules ou occurrences}

Formulas  with fixed points support two notions of subformula. The first one is
 the usual notion of subformula: $\psi\leq \phi$ 
if the syntactic tree of $\psi$ is a subtree of the systactic tree of $\phi$. In general, the subformula of a closed formula may contain free variables.
The second one is specific to formulas with fixed points, 
it is a sort of subformula up to unfolding, so that the subformulas of a closed formula wrt. this notion are also closed; we call it \emph{Fischer-Ladner} subformula and introduce it below.

\begin{definition}\label{def:FLSubformula}
We define the relation $\rightarrow$ on  occurrences as follows, where $\star\in\{\vee, \wedge\}$:
\begin{center}
$\begin{array}{ll}
(\phi \star \psi)_\alpha \ \rightarrow \  \phi_{\alpha\Al} &
(\phi \star \psi)_\alpha \  \rightarrow \  \psi_{\alpha\Ar} \\[4pt]
(\odot\phi)_\alpha \ \rightarrow \  \phi_{\alpha\Ai} & 
(\sigma X. \phi)_\alpha \ \rightarrow \ (\phi[\sigma X. \phi/ X])_{\alpha\Ai} 
\end{array}$
\end{center}
A \defname{FL-suboccurrence} of  $F$ is any  $G$ such that 
$F\rightarrow^* G$, where $\rightarrow^*$ is the reflexive transitive closure of $\rightarrow$.  
The \defname{FL-subformulas} of $F$ are obtained by forgetting the adresses of its FL-suboccurrences.  
The \defname{Fisher-Ladner closure} of a formula occurrence, denoted $FL(F)$, is the set of its FL-subformulas. 
\end{definition}

\begin{example}\label{ex:FLclosure}
Let $\Phi=\mu X.\nu Y.  \odot X \wedge \odot Y$ and $\Psi= \nu Y. \odot \Phi \vee \odot Y$. One has for instance:
 $$\Phi_\epsilon\rightarrow \Psi_\Ai \rightarrow (\odot \Phi \vee \odot \Psi)_{\Ai\Ai}\rightarrow (\odot\Phi )_{\Ai\Ai\Al}\rightarrow \Phi_{\Ai\Ai\Al\Ai}\rightarrow \Psi_{\Ai\Ai\Al\Ai\Ai}$$
The Fisher-Ladner closure of $\Phi$ is $\{\Phi, \Psi, \odot \Phi \vee \odot \Psi, \odot \Psi, \odot \Phi\}$. 
\end{example}
\begin{proposition}\cite{}
The set $FL(F)$ is finite.
\end{proposition}
The FL-suboccurrences of $F$ are induced by traversals of the
\emph{graph} of $F$, which is the graph obtained from the tree of $F$, by adding the possibility of jumping from a variable to the fixed point combinator that introduced it. We make this observation more precise in the following.

\begin{definition}
The \defname{tree of a formula} $\phi$, denoted $\tau(\phi)$, is obtained from its syntactic tree of $\phi$ by  labelling  every edge $e$ as follows: if $e$ is the right (resp. left) outgoing edge of a binary connective, then it is labelled $\Ar$ (resp. $\Al$); otherwise it is labelled $\Ai$.  
The \defname{graph of a formula} $\phi$, denoted $\C{G}(\phi)$, is the rooted graph obtained from $\tau(\phi)$ by identifying the nodes of bound variables with their binders.  
\end{definition}

\begin{example}\label{ex:GraphesFormules}
Let $\Phi$ be the formula of Example~\ref{ex:FLclosure}. The tree and the graph of $\Phi$ are  the following:
  \begin{center}
 \scalebox{.89}{
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,semithick]
  
      \tikzstyle{level 1}=[level distance=.9cm, sibling distance=.8cm]
       \tikzstyle{state}=[draw=none]
     \node at (0,0) { $\tau(\Phi)$ }   ; 
     \node at (1,0) { $=$ }   ; 
  \node[state] (muX)   at (2,0)           {$\mu X$};
  \node[state] (nuY) [below of=muX] {$\nu Y$};
  \node[state] (and) [below of=nuY] {$\wedge$};
  \node[state] (nextR) [below right of=and] {$\Next$};
  \node[state] (nextL) [below left of=and]  {$\Next$};
 \node[state] (Y) [below of=nextR] {$Y$};
  \node[state] (X) [below of=nextL]  {$X$};


  \path (muX) edge            node {$\Ai$} (nuY)
        (nuY) edge            node {$\Ai$} (and)
        (and) edge             node {$\Ar$} (nextR)
        (and) edge             node [above] {$\Al$} (nextL)
        (nextL) edge  node {$\Ai$} (X)
        (nextR) edge  node [right] {$\Ai$} (Y);

     \node at (5,0) { $\C{G}(\Phi)$ }   ; 
     \node at (6,0) { $=$ }   ; 
  \node[state] (muX)   at (7,0)           {$\mu X$};
  \node[state] (nuY) [below of=muX] {$\nu Y$};
  \node[state] (and) [below of=nuY] {$\wedge$};
  \node[state] (nextR) [below right of=and] {$\Next$};
  \node[state] (nextL) [below left of=and]  {$\Next$};


  \path (muX) edge            node {$\Ai$} (nuY)
        (nuY) edge            node {$\Ai$} (and)
        (and) edge             node {$\Ar$} (nextR)
        (and) edge             node [above] {$\Al$} (nextL)
        (nextL) edge [bend left]          node {$\Ai$} (muX)
        (nextR) edge [bend right]         node [right] {$\Ai$} (nuY);
\end{tikzpicture}
}
\end{center}
\end{example}
\begin{terminology}
  When we speak about the relative positions of two nodes
 of $\C{G}(\phi)$  (above, below, closer to
the root) it is relatively to their positions in $\tau(\phi)$.
For instance, in  $\C{G}(\Phi)$ of Example~\ref{ex:GraphesFormules}, the two nodes labelled $\odot$ are below the node labelled 
$\nu Y$.
\end{terminology}

\begin{proposition} Let $F=\phi_\alpha$ be an occurrence. If $\psi_\beta$ is a FL-suboccurrence of $F$, then $\beta=\alpha.p$, where $p$ is a path  of 
$\C{G}(\phi)$ from the root to some node $n$; we denote this node by $\C{N}_{F}(\psi_\beta)$.
\end{proposition}

\begin{definition}
A \defname{thread} of $F$ is a sequence $t=(F_i)_{i\in \omega}$  st. $F_0=F$ and
 $\forall i\in \omega,\ F_i\rightarrow F_{i+1}$.
\beginshort
Let $\overline{t}$ be the sequence $(\overline{F_i})_{i\in \omega}$.
\endshort
\beginlong
Let $\overline{t}$ be the sequence $(\overline{F_i})_{i\in \omega}$ \ie the sequence obtained by forgetting the adresses of the formula occurrences of $t$.
\endlong
 We denote by $Inf(t)$ the elements of $\overline{t}$ that appears infinitely often in $\overline{t}$. 
\end{definition}
\comad{Ajouter aux threads la possibilité de stationner.}
A thread $t$ starting from $F$ can be seen as a path in the graph $\C{G}(F)$.
Since $\overline{t}\subseteq FL(F)$, hence $Inf(\overline{t})$ is finite.
The following proposition shows moreover that the set $Inf(\overline{t})$ admits
a minimum wrt.\beginlong the subformula ordering\endlong $\leq$, and gives a graphical caracterisation of this minimum.   

\begin{proposition}\label{prop:MinISClosestToRoot}
Let $t=(F_i)_{i\in\omega}$ be a thread of an occurrence $F$. The set $Inf(\overline{t})$ admits a minimum wrt. $\leq$, we denote it $min(Inf(t))$.
Let $p=(\C{N}_{F}(F_i))_{i\in\omega}$ be the path of $\C{G}(F)$ made of the nodes
corresponding to the occurrences $F_i$ and $Inf(p)$ be the set of nodes that occurres infinitely often in $p$. The set  $Inf(p)$  contains a node $n$
which  is  the closest element of $Inf(p)$ to the root.  
If $k\in\omega$ is st. $n=\C{N}_{F}(F_k)$, then $\overline{F_k}=min(Inf(t))$. 
\end{proposition}

\begin{example} Let $t$ be the thread of $\Phi_\epsilon$ that goes to the right:
$t=\Phi_\epsilon\rightarrow \Psi_\Ai \rightarrow^\star \Psi_{\Ai\Ai\Ar\Ai} \rightarrow^\star\Psi_{\Ai\Ai\Ar\Ai\Ai\Ar\Ai}\dots $
One has $Inf(\overline{t})=\{\Psi, (\odot\Phi \wedge \odot\Psi), \odot\Psi \}$
and $min(Inf(t))=\Psi$.
\beginlong
The thread $t$ describes the path $n_{\mu}(n_{\nu} n_\vee n_{\odot_r})^\omega$, where $n_\mu, n_{\nu}, n_{\vee}$ are respectively the nodes labelled $\mu X, \nu Y, \wedge$, and
$n_{\odot_r}$ is the right node labelled $\odot$.
 $Inf(p)$ is the set of nodes $\{n_\nu , n_\vee, n_{\odot_r}\}$, and the closest node of  $Inf(p)$ to the root is the node $n_\nu $ which is the node of $\Psi_\Ai$.
\endlong

\end{example}


We are now ready to introduce our sequent calculus.

\subsubsection{Circular proof system}

\begin{figure}[t]
  \centering
\scalebox{.95}{
$\begin{array}{l}
\begin{prooftree}
\Hypo{\Gamma, F\vdash \Delta}
\Hypo{\Gamma \vdash F, \Delta}
\Infer{2}[\rcut]{\Gamma \vdash \Delta}
\end{prooftree}
\quad\quad
  \begin{prooftree}
  \Hypo{\Sigma\vdash \Theta}
  \Infer{1}[\rnext]{
    \Next \Sigma\vdash \Next \Theta}
  \end{prooftree}
\\[10pt]
\begin{prooftree}
\Hypo{}
\Infer{1}[\rax]{F \vdash F}
\end{prooftree}
\quad
\begin{prooftree}
  \Hypo{\Gamma\vdash \Delta}
  \Infer{1}[\!\!\rweakl]{
    \Gamma, F \vdash \Delta}
  \end{prooftree}
\quad\quad 
 \begin{prooftree}
  \Hypo{\Gamma\vdash \Delta}
  \Infer{1}[\!\!\rweakr]{
    \Gamma \vdash F, \Delta}
  \end{prooftree}
\\[10pt]
\begin{prooftree}
\Hypo{\Gamma, F\vdash \Delta}
\Hypo{\Gamma, G\vdash \Delta}
\Infer{2}[\rdisjl]{\Gamma, F\vee G \vdash \Delta}
\end{prooftree}
\quad\quad
\begin{prooftree}
\Hypo{\Gamma\vdash F, G, \Delta}
\Infer{1}[\rdisjr]{\Gamma\vdash F\vee G, \Delta}
\end{prooftree}
\\[10pt]
\begin{prooftree}
\Hypo{\Gamma, F,G\vdash \Delta}
\Infer{1}[\rconjl]{\Gamma, F\wedge G\vdash \Delta}
\end{prooftree}
\quad\quad
\begin{prooftree}
\Hypo{\Gamma\vdash F,\Delta}
\Hypo{\Gamma\vdash G,\Delta}
\Infer{2}[\rconjr]{\Gamma\vdash F\wedge G, \Delta}
\end{prooftree}
  \end{array}$
}
%%%  
\caption{Inference rules for propositional connectives.}
\label{fig:mulkiProp}
\end{figure}
\begin{figure}[t]
\centering
$
\begin{array}{cc}
\begin{prooftree}
\Hypo{\Gamma, F[\sigma X.F/X] \vdash \Delta}
\Infer{1}[\rsigmal]{ \Gamma,\sigma X.F \vdash \Delta}
\end{prooftree}
& 
\begin{prooftree}
\Hypo{\Gamma \vdash G[\sigma X.G/X], \Delta}
\Infer{1}[\rsigmar]{\Gamma \vdash \sigma X.G, \Delta}
\end{prooftree}
%\\[20pt]
\end{array}$
\caption{Fixed point rules for the \muLKi proof system.}
\label{fig:mulkiFP}
\end{figure}
\begin{definition}
A \defname{sequent}, written $\Delta\vdash\Gamma$,
is pair of two  finite sets of pairwise disjoint occurrences.
A \defname{pre-proof} of \muLKi is a possibly infinite tree, coinductively
generated by the rules of Figure~\ref{fig:mulkiProp} and~\ref{fig:mulkiFP}.
\end{definition}

The disjointness condition on sequents ensures that two occurrences
from the same sequent will never engender a common sub-occurrence.
Note that if the disjointness condition is satisfied for the conclusion sequent of a pre-proof, then all the sequents of this pre-proof satisfy it. 


Pre-proofs are  unsound: it is easy to derive the formula $\mu X. \odot X$, which is semantically equivalent to $\bot$, by applying coinductively $\rmur$ rule followed by $\rnext$ rule.
In order to obtain proper proofs from pre-proofs,
we will add a validity condition. This condition will reflect the
nature of our two fixed point connectives.

\begin{definition}
A thread $t$ is said a \defname{$\mu$-thread} (resp. \defname{$\nu$-thread}) if
$min(Inf(\overline{t}))$ is a $\mu$ (resp. $\nu$) formula.

Let $\gamma=(\Delta_i\vdash \Gamma_i)_{i\in\omega}$ be an infinite branch in a pre-proof of \muLKi. A \defname{thread} $t=(F_i)_{i\in\omega}$ is a right (resp. left) thread of $\gamma$ if $\forall i\in\omega,\ $ $F_i\in\Gamma_i$ (resp. $F_i\in\Gamma_i$). The branch $\gamma$ is said \defname{valid} if it contains a right $\nu$-thread
or a left $\mu$-thread which is not stationary.
\end{definition}

\begin{definition}
  The \defname{proofs} of \muLKi are those pre-proofs
  in which every infinite branch is valid.
\end{definition}
\beginlong
This validity condition has its roots in parity games and is very
natural for infinitary proof systems with fixed points.
It is commonly found in deductive systems for modal $\mu$-calculi: see
\cite{dax06fsttcs} for a closely related presentation, which yields
a sound and complete sequent calculus for linear time $\mu$-calculus.
\endlong

In this work, we will be interested in a subsystem of \muLKi whose proofs 
are \emph{finitely} representable, we call it \muLKo.

\begin{definition}
Let $\Pi, \Theta$ be \muLKi proofs of $\phi_\alpha$ and  $\phi_\beta$
respectively. We say that $\Pi$ and $\Theta$ are \defname{equal up to renaming}, and write $\Pi\equiv\Theta$, if $\Pi=\Theta[\alpha/\beta]$.
The relation $\equiv$ generalizes easily to proofs of conclusions with  multiple occurrences.
\end{definition}

\begin{definition}
 The \defname{circular proof sytem} \muLKo is the subsystem of \muLKi where derivations have only finitely many subderivations up to renaming.
\end{definition}

The proofs of \muLKo are called circular because they can be
 represented by trees with loops, as shown in the following example. 

\begin{example}
The \muLKo proof of $\top=\nu X. \odot X$ is the following, where we indicated that there is a loop using a symbol $(\star)$:
\begin{center}
\scalebox{.95}{
$\begin{prooftree}
\Hypo{(\star)}
\Infer{1}{\vdash \top_{\Ai\Ai}}
\Infer{1}[\rnext]{\vdash (\odot\top)_\Ai}
\Infer{1}[\rnur]{ \vdash \top_\epsilon \quad (\star)}
\end{prooftree}$}
\end{center}
\end{example}


\subsubsection{Finitary proof system}
We present now the system \muLK, which is the sequent calculus version of 
Kaivoila's axiomatization for linear time \mucalculus, and our target system for completeness.
\begin{figure}
\centering
$
\begin{array}{cc}
\begin{prooftree}
\Hypo{F[S/X] \vdash S}
\Infer{1}[\rmul]{ \mu X.F \vdash S}
\end{prooftree}
&
\begin{prooftree}
\Hypo{\Gamma \vdash F[ \mu X.F/X], \Delta}
\Infer{1}[\rmur]{\Gamma \vdash \mu X.F, \Delta}
\end{prooftree}
\\[12pt]
\begin{prooftree}
\Hypo{\Gamma, F[ \nu X.F/X] \vdash \Delta}
\Infer{1}[\rnul]{ \Gamma, \nu X.F \vdash \Delta}
\end{prooftree}
&
\begin{prooftree}
\Hypo{S \vdash F[S/X]}
\Infer{1}[\rnur]{ S \vdash \nu X.F}
\end{prooftree}
\end{array}
$
\caption{Fixed point rules for the \muLK proof system.}
\label{fig:mulk}
\end{figure}

\begin{definition}
  The proofs of \muLK are finite trees inductively generated
  from the rules of Figures~\ref{fig:mulkiProp} and \ref{fig:mulk}.
\end{definition}

The fixed point rules of Figure~\ref{fig:mulk} express that $\mu X. F$
is the least pre-fixed point of $X \mapsto F$, and dually for
$\nu X. F$.
Indeed, Knaster-Tarski theorem characterizes the least fixed point $\lfp(F)$ of
a monotonic operator $F: X\mapsto F(X)$ over a complete lattice $(L,\sqsubseteq)$ as the least pre-fixed point of $F$, ie:
\begin{itemize}
\item $F(\lfp(F))\sqsubseteq \lfp(F)$ ($\lfp(F)$ is a pre-fixed point);
\item $\forall S\in L,\quad F(S)\sqsubseteq S \Rightarrow \lfp(F)\sqsubseteq S$.
\end{itemize}
The rule $\rmur$ reflects the first part of the characterization while $\rmul$ reflects the second one.

\begin{definition}
 A formula $F$ is \defname{guarded} if every bound variable of $F$ appear under the scope  of a $\odot$ connective.    
\end{definition}
In \cite{} it is shown that every formula if provably equivalent to a guarded formula in \muLKo, and this proof is constructive. 

\paragraph{Proviso} If not otherwise stated all formulas are assumed to be 
closed, guarded, $\top$ and $\bot$ free. By earlier abservations, this is not a restriction. 


\subsubsection{Relating the infinitary and the finitary proof systems}

Finitary proofs can be easily transformed into circular ones,
but 
 giving an effective transformation
 from cirular to finitary proofs still an open problem.  However \cite{doumane16lics} give a condition on \muLKo proofs, sufficient to translate them effectively into \muLK ones. This
condition is much involved and we do not need it here in all its generality.
A weaker condition, presented below, will be used instead.  

\begin{definition}
  A \muLKo proof is \defname{easy} if all the occurrences of $\rsigmar$ and $\rsigmal$
  are of the following form, \ie there is no context around the unfolded formulas:
$$\begin{array}{cc}
\begin{prooftree}
\Hypo{ F[\sigma X.F/X] \vdash \Delta}
\Infer{1}[\rsigmal]{ \sigma X.F \vdash \Delta}
\end{prooftree}
& 
\begin{prooftree}
\Hypo{\Gamma \vdash G[\sigma X.G/X]}
\Infer{1}[\rsigmar]{\Gamma \vdash \sigma X.G}
\end{prooftree}
\end{array} $$ 
  
\end{definition}

\begin{proposition}\label{prop:easyIsTranslatable}
If $\pi$ is an easy proof of a sequent $s$, then it can be transformed effectively into a \muLK proof of $s$.
\end{proposition}

\beginlong
\begin{proof}
It suffices to notice that in an easy derivation every valid branch is strongly valid (Definition~29 of \cite{}). Hence
every easy proof is translatable (Definition~29 of \cite{}), by Proposition~30 of \cite{}, it can be transformed effectively unto a \muLK proof of the same sequent.   
\end{proof}
\endlong









